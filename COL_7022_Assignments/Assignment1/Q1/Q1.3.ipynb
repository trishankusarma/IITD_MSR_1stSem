{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stationary Environment but with optimal VI algorithms\n"
     ]
    }
   ],
   "source": [
    "from env import FootballSkillsEnv\n",
    "from model import model\n",
    "from policyIterationAlgo import policyIterationAlgo\n",
    "from valueIterationAlgo import valueIterationAlgo\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "    Key Environment Methods to Use:\n",
    "    - env.state_to_index(state_tuple): Converts (x, y, has_shot) tuple to integer index\n",
    "    - env.index_to_state(index): Converts in   teger index back to (x, y, has_shot) tuple\n",
    "    - env.get_transitions_at_time(state, action, time_step=None): Default method for accessing transitions.\n",
    "    - env._is_terminal(state): Check if state is terminal (has_shot=True)\n",
    "    - env._get_reward(ball_pos, action, player_pos): Get reward for transition\n",
    "    - env.reset(seed=None): Reset environment to initial state, returns (observation, info)\n",
    "    - env.step(action): Execute action, returns (obs, reward, done, truncated, info)\n",
    "    - env.get_gif(policy, seed=20, filename=\"output.gif\"): Generate GIF visualization \n",
    "      of policy execution from given seed\n",
    "    \n",
    "    Key Env Variables Notes:\n",
    "    - env.observation_space.n: Total number of states (use env.grid_size^2 * 2)\n",
    "    - env.action_space.n: Total number of actions (7 actions: 4 movement + 3 shooting)\n",
    "    - env.grid_size: Total number of rows in the grid\n",
    "    \n",
    "Implement the modified Value Iteration algorithm and run it for the Stationary Environment. Justify your\n",
    "design choices\n",
    "Idea : We need to think of a way to priortize the states with more maxDiff in order to acheive quicker convergence and also in addition \n",
    "to reduce the computations of the stationary states\n",
    "\n",
    "Algorithm \n",
    "1. First create a priority queue, do one round of belmann value funtion evaluation(maxm one) push the states with the maxDiff based on the current initialization\n",
    "2. Next start poping the elements from the priority queue ::\n",
    " # now we have the one with maxm diff \n",
    "     -> do one more round of value evaluation for that state\n",
    "     -> if the diff is more than threshold -> find the predecessors and push to the PQ\n",
    "3. Once done with value evaluation priority queue thing -- next do the policy improvement step\n",
    "\n",
    "Notice ::\n",
    "One subtle thing we need here is for the predecessors states for state s\n",
    "We need to implement that thing here first\n",
    "'''\n",
    "print(\"Starting Stationary Environment but with optimal VI algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of possible states : 800\n",
      "Total actions :  7\n",
      "Shape of policy matrix (800,) and shape of valueFn (800,)\n",
      "Curr iteration : 9800\n",
      "Curr iteration : 16800\n",
      "Curr iteration : 23800\n",
      "Curr iteration : 30800\n",
      "Curr iteration : 37800\n",
      "Curr iteration : 44800\n",
      "Curr iteration : 51800\n",
      "Count of total number of calls made to the  env.get_transitions_at_time is :  69048\n",
      "The value iteration converged after 1 outer_iterations, 7864 inner_iterations and 69048 calls to getTransisions_fn\n"
     ]
    }
   ],
   "source": [
    "optimal_policy_vi, optimal_valueFn_vi, outer_num_iterations_vi, inner_num_iterations_vi, calls_to_getTransisions_fn_vi = valueIterationAlgo(modified_VI = True)\n",
    "\n",
    "print(f\"The value iteration converged after {outer_num_iterations_vi} outer_iterations, {inner_num_iterations_vi} inner_iterations and {calls_to_getTransisions_fn_vi} calls to getTransisions_fn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value iteration converged after 1 outer_iterations, 7864 inner_iterations and 63448 calls to getTransisions_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
