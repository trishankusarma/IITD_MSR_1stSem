{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from naive_bayes import NaiveBayes\n",
    "from utils import tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary, getTrainingAndTestingData, plot_wordclouds_per_class, display_results_table\n",
    "from modelUtils import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape : (140000, 3)\n",
      "   label                              title  \\\n",
      "0      3                          Ernie Cox   \n",
      "1     10                          Holosteum   \n",
      "2      9                Pestarella tyrrhena   \n",
      "3      1          MidSun Junior High School   \n",
      "4      6  St James' Church Wrightington Bar   \n",
      "\n",
      "                                             content  \n",
      "0   Ernest Ernie Cox (February 17 1894 – February...  \n",
      "1   Holosteum is a genus of plants in the Pink fa...  \n",
      "2   Pestarella tyrrhena (formerly Callianassa tyr...  \n",
      "3   MidSun Junior High School is a Canadian middl...  \n",
      "4   St James' Church Wrightington Bar is in Churc...  \n",
      "df_test.shape : (35000, 3)\n",
      "   label                          title  \\\n",
      "0      4                   Lajos Drahos   \n",
      "1      5          USS Huntsville (1857)   \n",
      "2      0                         SCAFCO   \n",
      "3      6               McLean's Mansion   \n",
      "4      5  Avioane Craiova IAR-93 Vultur   \n",
      "\n",
      "                                             content  \n",
      "0   Lajos Drahos (7 March 1895 - 2 June 1983) was...  \n",
      "1   USS Huntsville was a steamer acquired by the ...  \n",
      "2   Founded in 1954 by Ben G. Stone SCAFCO Corpor...  \n",
      "3   McLean's Mansion (originally Holly Lea) is a ...  \n",
      "4   The Avioane Craiova IAR-93 Vultur (Eagle) is ...  \n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "print(f\"df_train.shape : {df_train.shape}\")\n",
    "\n",
    "print(df_train.head())\n",
    "\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "print(f\"df_test.shape : {df_test.shape}\")\n",
    "\n",
    "print(df_test.head())\n",
    "\n",
    "results = {}\n",
    "df_train[\"combined\"] = df_train[\"title\"] + \" \" + df_train[\"content\"]\n",
    "df_test[\"combined\"] = df_test[\"title\"] + \" \" + df_test[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [ernie, cox, ernest, ernie, cox, (february, 17...            3\n",
      "1  [holosteum, holosteum, is, a, genus, of, plant...           10\n",
      "2  [pestarella, tyrrhena, pestarella, tyrrhena, (...            9\n",
      "3  [midsun, junior, high, school, midsun, junior,...            1\n",
      "4  [st, james', church, wrightington, bar, st, ja...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajos, drahos, lajos, drahos, (7, march, 1895...            4\n",
      "1  [uss, huntsville, (1857), uss, huntsville, was...            5\n",
      "2  [scafco, founded, in, 1954, by, ben, g., stone...            0\n",
      "3  [mclean's, mansion, mclean's, mansion, (origin...            6\n",
      "4  [avioane, craiova, iar-93, vultur, the, avioan...            5\n",
      "--------UNIGRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 430904\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 430904)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 99.09%\n",
      "\n",
      "Class 0 -> Precision: 0.9850, Recall: 0.9618, F1-Score: 0.9733\n",
      "Class 1 -> Precision: 0.9869, Recall: 0.9952, F1-Score: 0.9910\n",
      "Class 2 -> Precision: 0.9923, Recall: 0.9831, F1-Score: 0.9877\n",
      "Class 3 -> Precision: 0.9939, Recall: 0.9981, F1-Score: 0.9960\n",
      "Class 4 -> Precision: 0.9918, Recall: 0.9941, F1-Score: 0.9930\n",
      "Class 5 -> Precision: 0.9917, Recall: 0.9975, F1-Score: 0.9946\n",
      "Class 6 -> Precision: 0.9860, Recall: 0.9854, F1-Score: 0.9857\n",
      "Class 7 -> Precision: 0.9905, Recall: 0.9985, F1-Score: 0.9945\n",
      "Class 8 -> Precision: 0.9999, Recall: 0.9855, F1-Score: 0.9926\n",
      "Class 9 -> Precision: 0.9996, Recall: 0.9949, F1-Score: 0.9972\n",
      "Class 10 -> Precision: 0.9988, Recall: 0.9978, F1-Score: 0.9983\n",
      "Class 11 -> Precision: 0.9827, Recall: 0.9984, F1-Score: 0.9905\n",
      "Class 12 -> Precision: 0.9907, Recall: 0.9943, F1-Score: 0.9925\n",
      "Class 13 -> Precision: 0.9833, Recall: 0.9884, F1-Score: 0.9858\n",
      "\n",
      "Macro-Average F1 Score: 0.9909\n",
      "Overall Precision: 0.9909\n",
      "Overall Recall: 0.9909\n",
      "Overall F1 Score: 0.9909\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 95.79%\n",
      "\n",
      "Class 0 -> Precision: 0.9336, Recall: 0.8716, F1-Score: 0.9015\n",
      "Class 1 -> Precision: 0.9533, Recall: 0.9792, F1-Score: 0.9661\n",
      "Class 2 -> Precision: 0.9368, Recall: 0.8900, F1-Score: 0.9128\n",
      "Class 3 -> Precision: 0.9809, Recall: 0.9836, F1-Score: 0.9822\n",
      "Class 4 -> Precision: 0.9588, Recall: 0.9772, F1-Score: 0.9679\n",
      "Class 5 -> Precision: 0.9693, Recall: 0.9852, F1-Score: 0.9772\n",
      "Class 6 -> Precision: 0.9532, Recall: 0.9456, F1-Score: 0.9494\n",
      "Class 7 -> Precision: 0.9623, Recall: 0.9896, F1-Score: 0.9757\n",
      "Class 8 -> Precision: 0.9987, Recall: 0.9488, F1-Score: 0.9731\n",
      "Class 9 -> Precision: 0.9915, Recall: 0.9756, F1-Score: 0.9835\n",
      "Class 10 -> Precision: 0.9872, Recall: 0.9848, F1-Score: 0.9860\n",
      "Class 11 -> Precision: 0.9424, Recall: 0.9880, F1-Score: 0.9647\n",
      "Class 12 -> Precision: 0.9374, Recall: 0.9708, F1-Score: 0.9538\n",
      "Class 13 -> Precision: 0.9070, Recall: 0.9204, F1-Score: 0.9136\n",
      "\n",
      "Macro-Average F1 Score: 0.9577\n",
      "Overall Precision: 0.9579\n",
      "Overall Recall: 0.9579\n",
      "Overall F1 Score: 0.9579\n"
     ]
    }
   ],
   "source": [
    "# Question Part 1 :: Unigram without stemming and removing stop words\n",
    "# Train the model with context and title concatenated only corresponding to the labels\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [1])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [1])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "    \n",
    "# 1. unigram - without stem - without stop words - done\n",
    "model = NaiveBayes() \n",
    "print(\"--------UNIGRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\")\n",
    "results[\"UNIGRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1, text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [erni, cox, ernest, erni, cox, (februari, 17, ...            3\n",
      "1  [holosteum, holosteum, genu, plant, pink, fami...           10\n",
      "2  [pestarella, tyrrhena, pestarella, tyrrhena, (...            9\n",
      "3  [midsun, junior, high, school, midsun, junior,...            1\n",
      "4  [st, james', church, wrightington, bar, st, ja...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajo, draho, lajo, draho, (7, march, 1895, -,...            4\n",
      "1  [uss, huntsvil, (1857), uss, huntsvil, steamer...            5\n",
      "2  [scafco, found, 1954, ben, g., stone, scafco, ...            0\n",
      "3  [mclean', mansion, mclean', mansion, (origin, ...            6\n",
      "4  [avioan, craiova, iar-93, vultur, avioan, crai...            5\n",
      "--------UNIGRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 405288\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 405288)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 98.83%\n",
      "\n",
      "Class 0 -> Precision: 0.9796, Recall: 0.9437, F1-Score: 0.9613\n",
      "Class 1 -> Precision: 0.9857, Recall: 0.9937, F1-Score: 0.9897\n",
      "Class 2 -> Precision: 0.9899, Recall: 0.9736, F1-Score: 0.9817\n",
      "Class 3 -> Precision: 0.9936, Recall: 0.9975, F1-Score: 0.9956\n",
      "Class 4 -> Precision: 0.9902, Recall: 0.9931, F1-Score: 0.9917\n",
      "Class 5 -> Precision: 0.9899, Recall: 0.9971, F1-Score: 0.9935\n",
      "Class 6 -> Precision: 0.9850, Recall: 0.9821, F1-Score: 0.9835\n",
      "Class 7 -> Precision: 0.9914, Recall: 0.9984, F1-Score: 0.9949\n",
      "Class 8 -> Precision: 0.9999, Recall: 0.9870, F1-Score: 0.9934\n",
      "Class 9 -> Precision: 0.9997, Recall: 0.9962, F1-Score: 0.9979\n",
      "Class 10 -> Precision: 0.9987, Recall: 0.9980, F1-Score: 0.9983\n",
      "Class 11 -> Precision: 0.9719, Recall: 0.9981, F1-Score: 0.9848\n",
      "Class 12 -> Precision: 0.9870, Recall: 0.9933, F1-Score: 0.9901\n",
      "Class 13 -> Precision: 0.9743, Recall: 0.9844, F1-Score: 0.9793\n",
      "\n",
      "Macro-Average F1 Score: 0.9883\n",
      "Overall Precision: 0.9883\n",
      "Overall Recall: 0.9883\n",
      "Overall F1 Score: 0.9883\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 94.95%\n",
      "\n",
      "Class 0 -> Precision: 0.9128, Recall: 0.8412, F1-Score: 0.8755\n",
      "Class 1 -> Precision: 0.9461, Recall: 0.9768, F1-Score: 0.9612\n",
      "Class 2 -> Precision: 0.9134, Recall: 0.8392, F1-Score: 0.8747\n",
      "Class 3 -> Precision: 0.9805, Recall: 0.9844, F1-Score: 0.9824\n",
      "Class 4 -> Precision: 0.9548, Recall: 0.9708, F1-Score: 0.9627\n",
      "Class 5 -> Precision: 0.9624, Recall: 0.9828, F1-Score: 0.9725\n",
      "Class 6 -> Precision: 0.9523, Recall: 0.9420, F1-Score: 0.9471\n",
      "Class 7 -> Precision: 0.9653, Recall: 0.9896, F1-Score: 0.9773\n",
      "Class 8 -> Precision: 0.9983, Recall: 0.9516, F1-Score: 0.9744\n",
      "Class 9 -> Precision: 0.9919, Recall: 0.9764, F1-Score: 0.9841\n",
      "Class 10 -> Precision: 0.9848, Recall: 0.9848, F1-Score: 0.9848\n",
      "Class 11 -> Precision: 0.9188, Recall: 0.9824, F1-Score: 0.9495\n",
      "Class 12 -> Precision: 0.9251, Recall: 0.9680, F1-Score: 0.9461\n",
      "Class 13 -> Precision: 0.8880, Recall: 0.9036, F1-Score: 0.8957\n",
      "\n",
      "Macro-Average F1 Score: 0.9491\n",
      "Overall Precision: 0.9495\n",
      "Overall Recall: 0.9495\n",
      "Overall F1 Score: 0.9495\n"
     ]
    }
   ],
   "source": [
    "# Question 1, part 2 :: Unigram with stemming and removing stop words\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [1])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [1])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "\n",
    "model = NaiveBayes()\n",
    "print(\"--------UNIGRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\")\n",
    "results[\"UNIGRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1, text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [erni cox, cox ernest, ernest erni, erni cox, ...            3\n",
      "1  [holosteum holosteum, holosteum genu, genu pla...           10\n",
      "2  [pestarella tyrrhena, tyrrhena pestarella, pes...            9\n",
      "3  [midsun junior, junior high, high school, scho...            1\n",
      "4  [st james', james' church, church wrightington...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajo draho, draho lajo, lajo draho, draho (7,...            4\n",
      "1  [uss huntsvil, huntsvil (1857), (1857) uss, us...            5\n",
      "2  [scafco found, found 1954, 1954 ben, ben g., g...            0\n",
      "3  [mclean' mansion, mansion mclean', mclean' man...            6\n",
      "4  [avioan craiova, craiova iar-93, iar-93 vultur...            5\n",
      "--------BIGRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 2348651\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 2348651)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 99.99%\n",
      "\n",
      "Class 0 -> Precision: 1.0000, Recall: 0.9998, F1-Score: 0.9999\n",
      "Class 1 -> Precision: 0.9996, Recall: 1.0000, F1-Score: 0.9998\n",
      "Class 2 -> Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 3 -> Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 4 -> Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 5 -> Precision: 1.0000, Recall: 0.9999, F1-Score: 0.9999\n",
      "Class 6 -> Precision: 0.9999, Recall: 0.9996, F1-Score: 0.9997\n",
      "Class 7 -> Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 8 -> Precision: 0.9999, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 9 -> Precision: 1.0000, Recall: 0.9998, F1-Score: 0.9999\n",
      "Class 10 -> Precision: 0.9998, Recall: 1.0000, F1-Score: 0.9999\n",
      "Class 11 -> Precision: 0.9999, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 12 -> Precision: 0.9999, Recall: 0.9999, F1-Score: 0.9999\n",
      "Class 13 -> Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "\n",
      "Macro-Average F1 Score: 0.9999\n",
      "Overall Precision: 0.9999\n",
      "Overall Recall: 0.9999\n",
      "Overall F1 Score: 0.9999\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 95.63%\n",
      "\n",
      "Class 0 -> Precision: 0.9291, Recall: 0.8808, F1-Score: 0.9043\n",
      "Class 1 -> Precision: 0.9420, Recall: 0.9876, F1-Score: 0.9643\n",
      "Class 2 -> Precision: 0.9502, Recall: 0.8548, F1-Score: 0.9000\n",
      "Class 3 -> Precision: 0.9679, Recall: 0.9884, F1-Score: 0.9780\n",
      "Class 4 -> Precision: 0.9372, Recall: 0.9728, F1-Score: 0.9547\n",
      "Class 5 -> Precision: 0.9701, Recall: 0.9748, F1-Score: 0.9725\n",
      "Class 6 -> Precision: 0.9589, Recall: 0.9420, F1-Score: 0.9504\n",
      "Class 7 -> Precision: 0.9637, Recall: 0.9888, F1-Score: 0.9761\n",
      "Class 8 -> Precision: 0.9947, Recall: 0.9752, F1-Score: 0.9849\n",
      "Class 9 -> Precision: 0.9860, Recall: 0.9560, F1-Score: 0.9708\n",
      "Class 10 -> Precision: 0.9576, Recall: 0.9848, F1-Score: 0.9710\n",
      "Class 11 -> Precision: 0.9412, Recall: 0.9920, F1-Score: 0.9659\n",
      "Class 12 -> Precision: 0.9574, Recall: 0.9796, F1-Score: 0.9684\n",
      "Class 13 -> Precision: 0.9332, Recall: 0.9108, F1-Score: 0.9219\n",
      "\n",
      "Macro-Average F1 Score: 0.9559\n",
      "Overall Precision: 0.9563\n",
      "Overall Recall: 0.9563\n",
      "Overall F1 Score: 0.9563\n"
     ]
    }
   ],
   "source": [
    "# Question 3 :: Bigram with stemming and removing stop words\n",
    "# 3. bigram - with stem - with stop words        -done\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [2])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [2])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "model = NaiveBayes()\n",
    "print(\"--------BIGRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\")\n",
    "results[\"BIGRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1, text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [ernie cox, cox ernest, ernest ernie, ernie co...            3\n",
      "1  [holosteum holosteum, holosteum is, is a, a ge...           10\n",
      "2  [pestarella tyrrhena, tyrrhena pestarella, pes...            9\n",
      "3  [midsun junior, junior high, high school, scho...            1\n",
      "4  [st james', james' church, church wrightington...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajos drahos, drahos lajos, lajos drahos, dra...            4\n",
      "1  [uss huntsville, huntsville (1857), (1857) uss...            5\n",
      "2  [scafco founded, founded in, in 1954, 1954 by,...            0\n",
      "3  [mclean's mansion, mansion mclean's, mclean's ...            6\n",
      "4  [avioane craiova, craiova iar-93, iar-93 vultu...            5\n",
      "--------BIGRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 2140570\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 2140570)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 99.97%\n",
      "\n",
      "Class 0 -> Precision: 0.9998, Recall: 0.9992, F1-Score: 0.9995\n",
      "Class 1 -> Precision: 0.9990, Recall: 0.9998, F1-Score: 0.9994\n",
      "Class 2 -> Precision: 0.9999, Recall: 0.9992, F1-Score: 0.9995\n",
      "Class 3 -> Precision: 0.9997, Recall: 0.9999, F1-Score: 0.9998\n",
      "Class 4 -> Precision: 0.9991, Recall: 0.9997, F1-Score: 0.9994\n",
      "Class 5 -> Precision: 0.9999, Recall: 0.9998, F1-Score: 0.9998\n",
      "Class 6 -> Precision: 0.9992, Recall: 0.9992, F1-Score: 0.9992\n",
      "Class 7 -> Precision: 0.9999, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 8 -> Precision: 0.9999, Recall: 0.9999, F1-Score: 0.9999\n",
      "Class 9 -> Precision: 1.0000, Recall: 0.9997, F1-Score: 0.9998\n",
      "Class 10 -> Precision: 0.9998, Recall: 0.9998, F1-Score: 0.9998\n",
      "Class 11 -> Precision: 0.9996, Recall: 0.9999, F1-Score: 0.9998\n",
      "Class 12 -> Precision: 0.9998, Recall: 0.9996, F1-Score: 0.9997\n",
      "Class 13 -> Precision: 1.0000, Recall: 0.9999, F1-Score: 0.9999\n",
      "\n",
      "Macro-Average F1 Score: 0.9997\n",
      "Overall Precision: 0.9997\n",
      "Overall Recall: 0.9997\n",
      "Overall F1 Score: 0.9997\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 97.11%\n",
      "\n",
      "Class 0 -> Precision: 0.9608, Recall: 0.9208, F1-Score: 0.9404\n",
      "Class 1 -> Precision: 0.9671, Recall: 0.9884, F1-Score: 0.9776\n",
      "Class 2 -> Precision: 0.9688, Recall: 0.9188, F1-Score: 0.9431\n",
      "Class 3 -> Precision: 0.9825, Recall: 0.9876, F1-Score: 0.9850\n",
      "Class 4 -> Precision: 0.9557, Recall: 0.9836, F1-Score: 0.9694\n",
      "Class 5 -> Precision: 0.9798, Recall: 0.9880, F1-Score: 0.9839\n",
      "Class 6 -> Precision: 0.9625, Recall: 0.9644, F1-Score: 0.9634\n",
      "Class 7 -> Precision: 0.9722, Recall: 0.9920, F1-Score: 0.9820\n",
      "Class 8 -> Precision: 1.0000, Recall: 0.9696, F1-Score: 0.9846\n",
      "Class 9 -> Precision: 0.9930, Recall: 0.9632, F1-Score: 0.9779\n",
      "Class 10 -> Precision: 0.9667, Recall: 0.9872, F1-Score: 0.9768\n",
      "Class 11 -> Precision: 0.9688, Recall: 0.9936, F1-Score: 0.9810\n",
      "Class 12 -> Precision: 0.9718, Recall: 0.9796, F1-Score: 0.9757\n",
      "Class 13 -> Precision: 0.9482, Recall: 0.9592, F1-Score: 0.9537\n",
      "\n",
      "Macro-Average F1 Score: 0.9710\n",
      "Overall Precision: 0.9711\n",
      "Overall Recall: 0.9711\n",
      "Overall F1 Score: 0.9711\n"
     ]
    }
   ],
   "source": [
    "# Question 3 :: Bigram without stemming or removing stop words\n",
    "# bigram - without stem - without stop words  - done\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [2])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [2])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "\n",
    "model = NaiveBayes()\n",
    "print(\"--------BIGRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\")\n",
    "results[\"BIGRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1,  text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [ernie, cox, ernest, ernie, cox, (february, 17...            3\n",
      "1  [holosteum, holosteum, is, a, genus, of, plant...           10\n",
      "2  [pestarella, tyrrhena, pestarella, tyrrhena, (...            9\n",
      "3  [midsun, junior, high, school, midsun, junior,...            1\n",
      "4  [st, james', church, wrightington, bar, st, ja...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajos, drahos, lajos, drahos, (7, march, 1895...            4\n",
      "1  [uss, huntsville, (1857), uss, huntsville, was...            5\n",
      "2  [scafco, founded, in, 1954, by, ben, g., stone...            0\n",
      "3  [mclean's, mansion, mclean's, mansion, (origin...            6\n",
      "4  [avioane, craiova, iar-93, vultur, the, avioan...            5\n",
      "--------UNI+BI+GRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 2571474\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 2571474)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 99.91%\n",
      "\n",
      "Class 0 -> Precision: 0.9989, Recall: 0.9973, F1-Score: 0.9981\n",
      "Class 1 -> Precision: 0.9977, Recall: 0.9994, F1-Score: 0.9986\n",
      "Class 2 -> Precision: 0.9993, Recall: 0.9981, F1-Score: 0.9987\n",
      "Class 3 -> Precision: 0.9994, Recall: 0.9998, F1-Score: 0.9996\n",
      "Class 4 -> Precision: 0.9984, Recall: 0.9992, F1-Score: 0.9988\n",
      "Class 5 -> Precision: 0.9993, Recall: 0.9996, F1-Score: 0.9995\n",
      "Class 6 -> Precision: 0.9981, Recall: 0.9983, F1-Score: 0.9982\n",
      "Class 7 -> Precision: 0.9987, Recall: 1.0000, F1-Score: 0.9994\n",
      "Class 8 -> Precision: 0.9999, Recall: 0.9986, F1-Score: 0.9992\n",
      "Class 9 -> Precision: 1.0000, Recall: 0.9995, F1-Score: 0.9997\n",
      "Class 10 -> Precision: 0.9996, Recall: 0.9991, F1-Score: 0.9993\n",
      "Class 11 -> Precision: 0.9986, Recall: 0.9996, F1-Score: 0.9991\n",
      "Class 12 -> Precision: 0.9995, Recall: 0.9989, F1-Score: 0.9992\n",
      "Class 13 -> Precision: 0.9994, Recall: 0.9994, F1-Score: 0.9994\n",
      "\n",
      "Macro-Average F1 Score: 0.9991\n",
      "Overall Precision: 0.9991\n",
      "Overall Recall: 0.9991\n",
      "Overall F1 Score: 0.9991\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 97.11%\n",
      "\n",
      "Class 0 -> Precision: 0.9562, Recall: 0.9072, F1-Score: 0.9310\n",
      "Class 1 -> Precision: 0.9671, Recall: 0.9868, F1-Score: 0.9768\n",
      "Class 2 -> Precision: 0.9678, Recall: 0.9244, F1-Score: 0.9456\n",
      "Class 3 -> Precision: 0.9849, Recall: 0.9892, F1-Score: 0.9870\n",
      "Class 4 -> Precision: 0.9644, Recall: 0.9852, F1-Score: 0.9747\n",
      "Class 5 -> Precision: 0.9783, Recall: 0.9896, F1-Score: 0.9839\n",
      "Class 6 -> Precision: 0.9616, Recall: 0.9624, F1-Score: 0.9620\n",
      "Class 7 -> Precision: 0.9691, Recall: 0.9912, F1-Score: 0.9800\n",
      "Class 8 -> Precision: 0.9996, Recall: 0.9616, F1-Score: 0.9802\n",
      "Class 9 -> Precision: 0.9955, Recall: 0.9740, F1-Score: 0.9846\n",
      "Class 10 -> Precision: 0.9821, Recall: 0.9888, F1-Score: 0.9854\n",
      "Class 11 -> Precision: 0.9610, Recall: 0.9960, F1-Score: 0.9782\n",
      "Class 12 -> Precision: 0.9753, Recall: 0.9800, F1-Score: 0.9777\n",
      "Class 13 -> Precision: 0.9353, Recall: 0.9596, F1-Score: 0.9473\n",
      "\n",
      "Macro-Average F1 Score: 0.9710\n",
      "Overall Precision: 0.9711\n",
      "Overall Recall: 0.9711\n",
      "Overall F1 Score: 0.9711\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with unigram and bi-gram -- WITHOUT PRE-PROCESSING\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [1,2])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = False, with_stemming = False, window = [1,2])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "\n",
    "model = NaiveBayes()\n",
    "print(\"--------UNI+BI+GRAM -- WITHOUT STEMMING -- WITHOUT STOP WORDS REMOVAL---------\")\n",
    "results[\"UNI+BI+GRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1,  text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [erni, cox, ernest, erni, cox, (februari, 17, ...            3\n",
      "1  [holosteum, holosteum, genu, plant, pink, fami...           10\n",
      "2  [pestarella, tyrrhena, pestarella, tyrrhena, (...            9\n",
      "3  [midsun, junior, high, school, midsun, junior,...            1\n",
      "4  [st, james', church, wrightington, bar, st, ja...            6\n",
      "\n",
      "Testing Data Sample:\n",
      "                               Tokenized Description  Class Index\n",
      "0  [lajo, draho, lajo, draho, (7, march, 1895, -,...            4\n",
      "1  [uss, huntsvil, (1857), uss, huntsvil, steamer...            5\n",
      "2  [scafco, found, 1954, ben, g., stone, scafco, ...            0\n",
      "3  [mclean', mansion, mclean', mansion, (origin, ...            6\n",
      "4  [avioan, craiova, iar-93, vultur, avioan, crai...            5\n",
      "--------UNI+BI+GRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\n",
      "Number of classes: 14, examples: 140000, vocab size: 2753939\n",
      "Shape of phi_y: (14,)\n",
      "Shape of phi_j_given_y: (14, 2753939)\n",
      "Evaluating on train data...\n",
      "Evaluating on 140000 examples\n",
      "Overall Accuracy: 99.96%\n",
      "\n",
      "Class 0 -> Precision: 0.9995, Recall: 0.9984, F1-Score: 0.9989\n",
      "Class 1 -> Precision: 0.9988, Recall: 0.9999, F1-Score: 0.9994\n",
      "Class 2 -> Precision: 0.9997, Recall: 0.9994, F1-Score: 0.9995\n",
      "Class 3 -> Precision: 0.9998, Recall: 0.9999, F1-Score: 0.9999\n",
      "Class 4 -> Precision: 0.9994, Recall: 0.9996, F1-Score: 0.9995\n",
      "Class 5 -> Precision: 0.9999, Recall: 0.9998, F1-Score: 0.9998\n",
      "Class 6 -> Precision: 0.9994, Recall: 0.9993, F1-Score: 0.9993\n",
      "Class 7 -> Precision: 0.9999, Recall: 1.0000, F1-Score: 1.0000\n",
      "Class 8 -> Precision: 0.9999, Recall: 0.9998, F1-Score: 0.9998\n",
      "Class 9 -> Precision: 1.0000, Recall: 0.9997, F1-Score: 0.9998\n",
      "Class 10 -> Precision: 0.9998, Recall: 0.9994, F1-Score: 0.9996\n",
      "Class 11 -> Precision: 0.9995, Recall: 0.9998, F1-Score: 0.9997\n",
      "Class 12 -> Precision: 0.9992, Recall: 0.9997, F1-Score: 0.9995\n",
      "Class 13 -> Precision: 0.9996, Recall: 0.9997, F1-Score: 0.9997\n",
      "\n",
      "Macro-Average F1 Score: 0.9996\n",
      "Overall Precision: 0.9996\n",
      "Overall Recall: 0.9996\n",
      "Overall F1 Score: 0.9996\n",
      "Evaluating on test data...\n",
      "Evaluating on 35000 examples\n",
      "Overall Accuracy: 96.40%\n",
      "\n",
      "Class 0 -> Precision: 0.9455, Recall: 0.8744, F1-Score: 0.9086\n",
      "Class 1 -> Precision: 0.9585, Recall: 0.9876, F1-Score: 0.9728\n",
      "Class 2 -> Precision: 0.9509, Recall: 0.8752, F1-Score: 0.9115\n",
      "Class 3 -> Precision: 0.9829, Recall: 0.9900, F1-Score: 0.9864\n",
      "Class 4 -> Precision: 0.9592, Recall: 0.9776, F1-Score: 0.9683\n",
      "Class 5 -> Precision: 0.9682, Recall: 0.9864, F1-Score: 0.9772\n",
      "Class 6 -> Precision: 0.9622, Recall: 0.9572, F1-Score: 0.9597\n",
      "Class 7 -> Precision: 0.9737, Recall: 0.9920, F1-Score: 0.9828\n",
      "Class 8 -> Precision: 0.9988, Recall: 0.9672, F1-Score: 0.9827\n",
      "Class 9 -> Precision: 0.9968, Recall: 0.9824, F1-Score: 0.9895\n",
      "Class 10 -> Precision: 0.9873, Recall: 0.9912, F1-Score: 0.9892\n",
      "Class 11 -> Precision: 0.9374, Recall: 0.9940, F1-Score: 0.9649\n",
      "Class 12 -> Precision: 0.9542, Recall: 0.9828, F1-Score: 0.9683\n",
      "Class 13 -> Precision: 0.9221, Recall: 0.9380, F1-Score: 0.9300\n",
      "\n",
      "Macro-Average F1 Score: 0.9637\n",
      "Overall Precision: 0.9640\n",
      "Overall Recall: 0.9640\n",
      "Overall F1 Score: 0.9640\n"
     ]
    }
   ],
   "source": [
    "# Tokenize with unigram and bi-gram -- WITH PRE-PROCESSING\n",
    "df_train, vocabulary = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_train, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [1,2])\n",
    "df_test, _ = tokenizeAndRemoveStopWordsOrStemAndReturnVocabulary(df_test, \"combined\", target_col = \"Tokenized Description\", remove_stop_words = True, with_stemming = True, window = [1,2])\n",
    "\n",
    "trainingData, testingData = getTrainingAndTestingData(df_train, df_test, target_field = \"Tokenized Description\")\n",
    "\n",
    "model = NaiveBayes()\n",
    "print(\"--------UNI+BI+GRAM -- WITH STEMMING -- WITH STOP WORDS REMOVAL---------\")\n",
    "results[\"UNI+BI+GRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\"] = run_model(model, vocabulary, trainingData, testingData, smoothening = 0.1,  text_col = \"Tokenized Description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Model: UNIGRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 99.09   │ 95.79   │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9909 │  0.9579 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9909 │  0.9579 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9909 │  0.9579 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9909 │  0.9577 │\n",
      "╘══════════════════════╧═════════╧═════════╛\n",
      "\n",
      "==========================================================================================\n",
      "Model: UNIGRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 98.83   │ 94.95   │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9883 │  0.9495 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9883 │  0.9495 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9883 │  0.9495 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9883 │  0.9491 │\n",
      "╘══════════════════════╧═════════╧═════════╛\n",
      "\n",
      "==========================================================================================\n",
      "Model: BIGRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 99.99   │ 95.63   │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9999 │  0.9563 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9999 │  0.9563 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9999 │  0.9563 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9999 │  0.9559 │\n",
      "╘══════════════════════╧═════════╧═════════╛\n",
      "\n",
      "==========================================================================================\n",
      "Model: BIGRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 99.97   │ 97.11   │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9997 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9997 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9997 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9997 │  0.971  │\n",
      "╘══════════════════════╧═════════╧═════════╛\n",
      "\n",
      "==========================================================================================\n",
      "Model: UNI+BI+GRAM-WITHOUT STEMMING-WITHOUT STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 99.91   │ 97.11   │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9991 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9991 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9991 │  0.9711 │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9991 │  0.971  │\n",
      "╘══════════════════════╧═════════╧═════════╛\n",
      "\n",
      "==========================================================================================\n",
      "Model: UNI+BI+GRAM-WITH STEMMING-WITH STOP WORDS REMOVAL\n",
      "==========================================================================================\n",
      "╒══════════════════════╤═════════╤═════════╕\n",
      "│ Metric               │   Train │    Test │\n",
      "╞══════════════════════╪═════════╪═════════╡\n",
      "│ Overall Accuracy (%) │ 99.96   │ 96.4    │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Precision    │  0.9996 │  0.964  │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall Recall       │  0.9996 │  0.964  │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Overall F1 Score     │  0.9996 │  0.964  │\n",
      "├──────────────────────┼─────────┼─────────┤\n",
      "│ Macro F1 Score       │  0.9996 │  0.9637 │\n",
      "╘══════════════════════╧═════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "display_results_table(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
